{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from my_modules.log import log,Limit,CounterBreak,CounterMod\n",
    "\n",
    "\n",
    "from my_modules.load_data import MyDataset,ConcatDataset\n",
    "import my_modules.model.lstm as model_modules\n",
    "from my_modules.model.lstm import LSTM_0,move_to_gpu,del_gpu,LSTM_1,LSTM_2,LSTM_3,LSTM_4\n",
    "\n",
    "from my_modules.model.lstmcnn_part3 import LSTMCNN_10,LSTMCNN_10_2\n",
    "from my_modules.model.lstm2cnn_part1 import LSTM2CNN_1,LSTM2CNN_2,LSTM2CNN_3,LSTM2CNN_4\n",
    "from my_modules.model.lstm2cnn_final import LSTM2CNN,LSTM2CNN_2\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import os\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(model_modules.get_used_memory())\n",
    "\n",
    "from playsound import playsound\n",
    "sound_path = r'C:\\Users\\rakna\\Desktop\\AIT_working\\AIT_CP_Project\\code\\notice_sound'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25156, 25156, 25156, 25156, 25156, 25156, 25156, 25156, 25156, 25156, 25156, 25156, 25156, 25156, 25156, 25156, 25156, 25156, 25156, 25156, 25156, 25156, 25156, 25156, 25156, 25156, 25156, 25156, 25156, 25156, 25156, 25156]\n",
      "804992\n",
      "(tensor([[ 2.6753e+00,  8.1925e+00,  1.8993e+01,  ..., -2.5978e+01,\n",
      "         -1.2039e+01, -3.2680e+00],\n",
      "        [-1.2657e+01, -2.5779e+01, -4.6467e+01,  ...,  6.1634e+01,\n",
      "          2.8586e+01, -1.3370e+00],\n",
      "        [-3.5147e+00, -3.1367e+00,  2.4314e+00,  ..., -5.2270e+00,\n",
      "         -4.0622e+00, -3.4219e+00],\n",
      "        ...,\n",
      "        [ 6.2441e+02,  5.8991e+02,  6.3266e+02,  ...,  6.3929e+02,\n",
      "          7.6063e+02,  8.4888e+02],\n",
      "        [ 2.6323e+03,  3.1801e+03,  3.6581e+03,  ...,  6.1361e+03,\n",
      "          6.2719e+03,  6.3632e+03],\n",
      "        [-3.8966e-02, -3.8966e-02, -3.8966e-02,  ...,  2.9033e-02,\n",
      "          2.9033e-02,  2.9033e-02]]), tensor([1., 9.]))\n"
     ]
    }
   ],
   "source": [
    "train_index_movie = [i for i in range(38)]\n",
    "test_index_movie = [i for i in range(len(train_index_movie),40)]\n",
    "\n",
    "\n",
    "people_name = []\n",
    "people_name = [*people_name,*[f's0{i}.dat' for i in range(1,9+1)]]\n",
    "people_name = [*people_name,*[f's{i}.dat' for i in range(10,32+1)]]\n",
    "data_root_path = r'C:\\Users\\rakna\\Desktop\\AIT_working\\AIT_CP_Project\\this_folder_git_ignore\\ori_datasets'\n",
    "\n",
    "data_path = [os.path.join(data_root_path,path) for path in people_name]\n",
    "\n",
    "\n",
    "\n",
    "# window_size = 145*5\n",
    "window_size = 145*10\n",
    "step_window = 10\n",
    "\n",
    "list_train_dataset = [MyDataset(_path,window_size,step_window,train_index_movie,do_noise=True) for _path in data_path]\n",
    "list_test_dataset = [MyDataset(_path,window_size,step_window,test_index_movie) for _path in data_path]\n",
    "\n",
    "\n",
    "data_train = ConcatDataset(*list_train_dataset)\n",
    "data_test = ConcatDataset(*list_test_dataset)\n",
    "\n",
    "\n",
    "print(data_train.len_of_dataset)\n",
    "print(len(data_train)) #804992\n",
    "print(data_train[50000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeForce GTX 1070 Ti\n"
     ]
    }
   ],
   "source": [
    "model_modules.do_gpu = torch.cuda.is_available()\n",
    "# model_modules.do_gpu = False\n",
    "\n",
    "if(model_modules.do_gpu):\n",
    "    print(torch.cuda.get_device_name())\n",
    "else:\n",
    "    print('using CPU')\n",
    "\n",
    "data_loader = DataLoader(data_train,batch_size = 128,shuffle=True,pin_memory=model_modules.do_gpu)\n",
    "data_loader_test  = DataLoader(data_test,batch_size = 128,shuffle=True,pin_memory=model_modules.do_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continue train from epoch 2 best_loss = 7.83\n"
     ]
    }
   ],
   "source": [
    "# input_size = num EEG channels\n",
    "\n",
    "\n",
    "input_size = 40\n",
    "torch.manual_seed(55555)\n",
    "\n",
    "\n",
    "save_folder = r'w_all\\v001'\n",
    "\n",
    "model = LSTM2CNN_2(input_size=input_size,number_layers=1)\n",
    "\n",
    "'''\n",
    "    load w\n",
    "    \n",
    "'''\n",
    "load_w_path = r'\\w_all\\v001\\model_002_7dot83'\n",
    "# load_w_path = None\n",
    "\n",
    "\n",
    "\n",
    "if(load_w_path is not None):\n",
    "    model.load_state_dict(torch.load(r'C:\\Users\\rakna\\Desktop\\AIT_working\\AIT_CP_Project\\this_folder_git_ignore'+load_w_path))\n",
    "\n",
    "best_loss = None\n",
    "epoch = -1\n",
    "if(load_w_path is not None):\n",
    "    name = load_w_path.split('\\\\')[-1]\n",
    "    epoch = int(name.split('_')[-2])\n",
    "    best_loss = float(name.split('_')[-1].replace('dot','.'))\n",
    "\n",
    "print(f\"continue train from epoch {epoch} best_loss = {best_loss}\")\n",
    "\n",
    "\n",
    "'''\n",
    "    tranfer learning\n",
    "'''\n",
    "\n",
    "\n",
    "# load_w_path = r'\\w\\v028\\model_036_0dot90'\n",
    "# load_w_path = r'\\w_s12\\v002\\model_013_4dot29'\n",
    "# model.load_state_dict(torch.load(r'C:\\Users\\rakna\\Desktop\\AIT_working\\AIT_CP_Project\\this_folder_git_ignore'+load_w_path))\n",
    "\n",
    "# epoch => what's epoch now\n",
    "\n",
    "\n",
    "model = move_to_gpu(model)\n",
    "# print(model.eval())\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "\n",
    "\n",
    "# lr_rate = 5e-8\n",
    "# lr_rate = 5e-7\n",
    "lr_rate = 5e-6\n",
    "# lr_rate = 5e-5\n",
    "# lr_rate = 5e-4\n",
    "# lr_rate = 5e-3\n",
    "# lr_rate = 1e-3\n",
    "\n",
    "\n",
    "\n",
    "l2_rate = 1e-4\n",
    "# l2_rate = 8e-3\n",
    "# l2_rate = 1e-3\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters_with_l2(),lr=lr_rate,weight_decay=l2_rate)\n",
    "optimizer_without_l2 = torch.optim.Adam(model.parameters_without_l2(),lr=lr_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                         | 0/6289 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continue train from epoch 2 best_loss = 7.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|██████████▎                                                                    | 823/6289 [06:42<44:33,  2.04it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-5a9d34efa19f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    104\u001b[0m                 \u001b[0mmodel_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m                 \u001b[0mmust_check\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m             \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m             \u001b[0mmodel_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m             \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-5a9d34efa19f>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(not_ok)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mloss_train_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_limit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch_gpu\\lib\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1170\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1171\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1172\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1173\u001b[0m                 \u001b[1;31m# Update and possibly print the progressbar.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch_gpu\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch_gpu\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 403\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    404\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch_gpu\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch_gpu\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\AIT_working\\AIT_CP_Project\\code\\001_get_start_with_code\\my_modules\\load_data.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m                 \u001b[0mindex_in_dataset\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mlen_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mwhich_dataset\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex_in_dataset\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\AIT_working\\AIT_CP_Project\\code\\001_get_start_with_code\\my_modules\\load_data.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, i)\u001b[0m\n\u001b[0;32m     81\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoise_mean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m                 noise = torch.normal(mean=noise_mean[i],\n\u001b[0m\u001b[0;32m     84\u001b[0m                         std=noise_std[i],size=(1,data.shape[-1]) )\n\u001b[0;32m     85\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(f\"continue train from epoch {epoch} best_loss = {best_loss}\")\n",
    "\n",
    "pl_1 = Limit(1)\n",
    "pl_1_2 = Limit(1)\n",
    "\n",
    "do_train = True\n",
    "is_limit = False\n",
    "\n",
    "def train(not_ok=0):\n",
    "    pl = Limit(3)\n",
    "    loss_train_batch = 0\n",
    "    c=0\n",
    "    for train_data,label in tqdm(data_loader):\n",
    "\n",
    "        if(is_limit):\n",
    "            if(CounterBreak.set_count(2).count()):\n",
    "                pl_1('limit train_data')\n",
    "                break\n",
    "\n",
    "        train_data = move_to_gpu(train_data)\n",
    "        label = move_to_gpu(label)\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        optimizer_without_l2.zero_grad()\n",
    "        bz = train_data.shape[0]\n",
    "        model.reset_hidden(bz)\n",
    "\n",
    "\n",
    "        if(not_ok==0):\n",
    "            y_hat = (model(train_data))\n",
    "        else:\n",
    "            model(1)\n",
    "\n",
    "        loss = loss_func(y_hat,label)\n",
    "        loss_train_batch+=float(loss)\n",
    "        c+=1\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer_without_l2.step()\n",
    "\n",
    "#         del_gpu(train_data,label)\n",
    "\n",
    "    log(loss_train_batch/c,title=f\"loss train at epoch {epoch}\")\n",
    "def model_eval():\n",
    "    '''\n",
    "                find loss test\n",
    "    '''\n",
    "    global best_loss\n",
    "    loss_test=0\n",
    "    c = 0\n",
    "    with torch.no_grad():\n",
    "        for test_data,y_test in tqdm(data_loader_test):\n",
    "\n",
    "\n",
    "            if(is_limit):\n",
    "                if(CounterBreak.set_count(2).count()):\n",
    "                    pl_1_2('limit test_data')\n",
    "                    break\n",
    "\n",
    "            test_data = move_to_gpu(test_data)    \n",
    "            y_test = move_to_gpu(y_test)\n",
    "\n",
    "            bz = test_data.shape[0]\n",
    "\n",
    "            model.reset_hidden(bz)\n",
    "            y_hat_test = model(test_data)\n",
    "\n",
    "            batch_loss_test = loss_func(y_hat_test,y_test)\n",
    "\n",
    "            loss_test+= float(batch_loss_test)\n",
    "            c+=1\n",
    "\n",
    "#             del_gpu(test_data,y_test)\n",
    "\n",
    "\n",
    "    loss_test = loss_test/c\n",
    "    log(loss_test,title=f\"loss_test at epoch {epoch}\")\n",
    "\n",
    "\n",
    "    rp = r\"C:\\Users\\rakna\\Desktop\\AIT_working\\AIT_CP_Project\\this_folder_git_ignore\"\n",
    "    if(CounterMod.init().set_mod(5).count()):\n",
    "        log(loss_test,title=f\"(from CounterMod)loss test at epoch {epoch}\")\n",
    "        log('ram gpu',torch.cuda.memory_allocated())\n",
    "        torch.save(model.state_dict(), os.path.join(rp,save_folder,f'./autosave_model_{epoch:03}_{\"{:.2f}\".format(loss_test).replace(\".\",\"dot\") }' ) )\n",
    "\n",
    "    if(best_loss is None or loss_test<best_loss):\n",
    "        best_loss=loss_test\n",
    "\n",
    "        torch.save(model.state_dict(), os.path.join(rp,save_folder,f'./model_{epoch:03}_{\"{:.2f}\".format(loss_test).replace(\".\",\"dot\") }' ) )\n",
    "        log(loss_test,title=f\"loss test at epoch {epoch}\")\n",
    "        log(title='save w',n=60)\n",
    "        playsound(os.path.join(sound_path,'got_it.mp3'))\n",
    "    else:\n",
    "        playsound(os.path.join(sound_path,'trying_best.mp3'))\n",
    "\n",
    "must_check =False\n",
    "if(do_train):\n",
    "    while True:\n",
    "        try:\n",
    "            epoch+=1    \n",
    "            if(must_check):\n",
    "                print(\"save check\")\n",
    "                model_eval()\n",
    "                must_check=False\n",
    "            train()\n",
    "            model_eval()\n",
    "    \n",
    "\n",
    "        except RuntimeError as e:\n",
    "            epoch-=1\n",
    "            playsound(os.path.join(sound_path,'help.mp3'))\n",
    "            print(\"Help me\"*10)\n",
    "            must_check=True\n",
    "            continue\n",
    "#             raise e\n",
    "# except TypeError:\n",
    "#     pass\n",
    "  \n",
    "\n",
    "# except KeyboardInterrupt:\n",
    "#     for sound in music_sheet2:\n",
    "#         winsound.Beep(sound[0], sound[1]) \n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
