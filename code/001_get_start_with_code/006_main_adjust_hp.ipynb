{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from my_modules.log import log,Limit,CounterBreak,CounterMod\n",
    "\n",
    "\n",
    "from my_modules.load_data import MyDataset\n",
    "import my_modules.model.lstm as model_modules\n",
    "from my_modules.model.lstm import LSTM_0,move_to_gpu,del_gpu,LSTM_1,LSTM_2,LSTM_3,LSTM_4\n",
    "\n",
    "from my_modules.model.lstmcnn_part3 import LSTMCNN_10,LSTMCNN_10_2\n",
    "from my_modules.model.lstm2cnn_part1 import LSTM2CNN_1,LSTM2CNN_2,LSTM2CNN_3,LSTM2CNN_4\n",
    "from my_modules.model.lstm2cnn_final import LSTM2CNN,LSTM2CNN_2\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import os\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(model_modules.get_used_memory())\n",
    "\n",
    "base_path = r\"/tf/notebooks\"\n",
    "\n",
    "\n",
    "from playsound import playsound\n",
    "sound_path = os.path.join(base_path,r'code\\notice_sound')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index_movie = [i for i in range(38)]\n",
    "test_index_movie = [i for i in range(len(train_index_movie),40)]\n",
    "\n",
    "data_path = os.path.join(base_path,r'this_folder_git_ignore/ori_datasets/s01.dat')\n",
    "# data_path = r\"/tf/notebooks/this_folder_git_ignore/ori_datasets/s01.dat\"\n",
    "\n",
    "\n",
    "# data_path = r'C:\\Users\\rakna\\Desktop\\AIT_working\\AIT_CP_Project\\this_folder_git_ignore\\ori_datasets\\s02.dat'\n",
    "# data_path = r'C:\\Users\\rakna\\Desktop\\AIT_working\\AIT_CP_Project\\this_folder_git_ignore\\ori_datasets\\s12.dat'\n",
    "# data_path = r'C:\\Users\\rakna\\Desktop\\AIT_working\\AIT_CP_Project\\this_folder_git_ignore\\ori_datasets\\s20.dat'\n",
    "# window_size = 145*5\n",
    "window_size = 145*10\n",
    "step_window = 10\n",
    "\n",
    "data_train = MyDataset(data_path,window_size,step_window,train_index_movie,do_noise=True)\n",
    "data_test = MyDataset(data_path,window_size,step_window,test_index_movie)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeForce GTX 1070 Ti\n"
     ]
    }
   ],
   "source": [
    "model_modules.do_gpu = torch.cuda.is_available()\n",
    "# model_modules.do_gpu = False\n",
    "\n",
    "if(model_modules.do_gpu):\n",
    "    print(torch.cuda.get_device_name())\n",
    "else:\n",
    "    print('using CPU')\n",
    "\n",
    "    \n",
    "batch_size_ = 16\n",
    "# batch_size_ = 64\n",
    "data_loader = DataLoader(data_train,batch_size = batch_size_,shuffle=True,pin_memory=model_modules.do_gpu)\n",
    "data_loader_test  = DataLoader(data_test,batch_size = batch_size_,shuffle=True,pin_memory=model_modules.do_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continue train from epoch -1 best_loss = None\n"
     ]
    }
   ],
   "source": [
    "# input_size = num EEG channels\n",
    "\n",
    "\n",
    "input_size = 40\n",
    "torch.manual_seed(55555)\n",
    "\n",
    "\n",
    "# save_folder = r'w/v029'\n",
    "save_folder = r'test'\n",
    "\n",
    "\n",
    "model = LSTM2CNN_2(input_size=input_size,number_layers=1,hidden_size=20)\n",
    "\n",
    "'''\n",
    "    load w\n",
    "    \n",
    "'''\n",
    "# load_w_path = r'w/v029/model_015_4dot18'\n",
    "load_w_path = None\n",
    "\n",
    "\n",
    "\n",
    "if(load_w_path is not None):\n",
    "    model.load_state_dict(torch.load(os.path.join(base_path,r'this_folder_git_ignore',load_w_path)))\n",
    "\n",
    "best_loss = None\n",
    "epoch = -1\n",
    "if(load_w_path is not None):\n",
    "    name = load_w_path.split('\\\\')[-1]\n",
    "    epoch = int(name.split('_')[-2])\n",
    "    best_loss = float(name.split('_')[-1].replace('dot','.'))\n",
    "\n",
    "print(f\"continue train from epoch {epoch} best_loss = {best_loss}\")\n",
    "\n",
    "\n",
    "'''\n",
    "    tranfer learning\n",
    "'''\n",
    "\n",
    "\n",
    "# load_w_path = r'\\w\\v028\\model_036_0dot90'\n",
    "# load_w_path = r'\\w_all\\v001\\model_009_7dot24'\n",
    "# model.load_state_dict(torch.load(r'C:\\Users\\rakna\\Desktop\\AIT_working\\AIT_CP_Project\\this_folder_git_ignore'+load_w_path))\n",
    "\n",
    "# epoch => what's epoch now\n",
    "\n",
    "\n",
    "model = move_to_gpu(model)\n",
    "# print(model.eval())\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "\n",
    "\n",
    "# lr_rate = 5e-8\n",
    "# lr_rate = 5e-7\n",
    "# lr_rate = 5e-6\n",
    "lr_rate = 5e-5\n",
    "# lr_rate = 5e-4\n",
    "# lr_rate = 5e-3\n",
    "# lr_rate = 1e-3\n",
    "\n",
    "\n",
    "\n",
    "l2_rate = 1e-4\n",
    "# l2_rate = 8e-3\n",
    "# l2_rate = 1e-3\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters_with_l2(),lr=lr_rate,weight_decay=l2_rate)\n",
    "optimizer_without_l2 = torch.optim.Adam(model.parameters_without_l2(),lr=lr_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1573 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continue train from epoch -1 best_loss = None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/1573 [00:00<08:42,  3.00it/s]\n",
      "  1%|          | 1/83 [00:00<00:14,  5.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit train_data\n",
      "==============================loss train at epoch 0==============================\n",
      "20.935619990030926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 3/83 [00:00<00:14,  5.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit test_data\n",
      "==============================loss_test at epoch 0==============================\n",
      "17.29184118906657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1573 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================loss test at epoch 0==============================\n",
      "17.29184118906657\n",
      "============================================================save w============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/1573 [00:00<07:25,  3.52it/s]\n",
      "  1%|          | 1/83 [00:00<00:13,  6.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================loss train at epoch 1==============================\n",
      "29.036780039469402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 3/83 [00:00<00:13,  6.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================loss_test at epoch 1==============================\n",
      "17.290613174438477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1573 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================loss test at epoch 1==============================\n",
      "17.290613174438477\n",
      "============================================================save w============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/1573 [00:00<07:28,  3.50it/s]\n",
      "  1%|          | 1/83 [00:00<00:13,  6.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================loss train at epoch 2==============================\n",
      "19.437995274861652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 3/83 [00:00<00:12,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================loss_test at epoch 2==============================\n",
      "16.078945795694988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1573 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================loss test at epoch 2==============================\n",
      "16.078945795694988\n",
      "============================================================save w============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/1573 [00:00<07:41,  3.40it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ace53d46a097>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mepoch\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m             \u001b[0mmodel_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-ace53d46a097>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mc\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0moptimizer_without_l2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(f\"continue train from epoch {epoch} best_loss = {best_loss}\")\n",
    "\n",
    "pl_1 = Limit(1)\n",
    "pl_1_2 = Limit(1)\n",
    "\n",
    "do_train = True\n",
    "is_limit = True\n",
    "\n",
    "def train():\n",
    "    pl = Limit(3)\n",
    "    loss_train_batch = 0\n",
    "    c=0\n",
    "    for train_data,label in tqdm(data_loader):\n",
    "\n",
    "        if(is_limit):\n",
    "            if(CounterBreak.set_count(2).count()):\n",
    "                pl_1('limit train_data')\n",
    "                break\n",
    "\n",
    "        train_data = move_to_gpu(train_data)\n",
    "        label = move_to_gpu(label)\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        optimizer_without_l2.zero_grad()\n",
    "        bz = train_data.shape[0]\n",
    "        model.reset_hidden(bz)\n",
    "\n",
    "\n",
    "\n",
    "        y_hat = (model(train_data))\n",
    "\n",
    "        loss = loss_func(y_hat,label)\n",
    "        loss_train_batch+=float(loss)\n",
    "        c+=1\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer_without_l2.step()\n",
    "\n",
    "        del_gpu(train_data,label)\n",
    "\n",
    "    log(loss_train_batch/c,title=f\"loss train at epoch {epoch}\")\n",
    "def model_eval():\n",
    "    '''\n",
    "                find loss test\n",
    "    '''\n",
    "    global best_loss\n",
    "    loss_test=0\n",
    "    c = 0\n",
    "    with torch.no_grad():\n",
    "        for test_data,y_test in tqdm(data_loader_test):\n",
    "\n",
    "\n",
    "            if(is_limit):\n",
    "                if(CounterBreak.set_count(2).count()):\n",
    "                    pl_1_2('limit test_data')\n",
    "                    break\n",
    "\n",
    "            test_data = move_to_gpu(test_data)    \n",
    "            y_test = move_to_gpu(y_test)\n",
    "\n",
    "            bz = test_data.shape[0]\n",
    "\n",
    "            model.reset_hidden(bz)\n",
    "            y_hat_test = model(test_data)\n",
    "\n",
    "            batch_loss_test = loss_func(y_hat_test,y_test)\n",
    "\n",
    "            loss_test+= float(batch_loss_test)\n",
    "            c+=1\n",
    "\n",
    "            del_gpu(test_data,y_test)\n",
    "\n",
    "\n",
    "    loss_test = loss_test/c\n",
    "    log(loss_test,title=f\"loss_test at epoch {epoch}\")\n",
    "\n",
    "\n",
    "    rp = os.path.join(base_path,r\"this_folder_git_ignore\")\n",
    "    if(CounterMod.init().set_mod(5).count()):\n",
    "        log(loss_test,title=f\"(from CounterMod)loss test at epoch {epoch}\")\n",
    "        log('ram gpu',torch.cuda.memory_allocated())\n",
    "        torch.save(model.state_dict(), os.path.join(rp,save_folder,f'autosave_model_{epoch:03}_{\"{:.2f}\".format(loss_test).replace(\".\",\"dot\") }' ) )\n",
    "\n",
    "    if(best_loss is None or loss_test<best_loss):\n",
    "        best_loss=loss_test\n",
    "\n",
    "        torch.save(model.state_dict(), os.path.join(rp,save_folder,f'model_{epoch:03}_{\"{:.2f}\".format(loss_test).replace(\".\",\"dot\") }' ) )\n",
    "        log(loss_test,title=f\"loss test at epoch {epoch}\")\n",
    "        log(title='save w',n=60)\n",
    "#         playsound(os.path.join(sound_path,'gotit.mp3'))\n",
    "    else:\n",
    "#         playsound(os.path.join(sound_path,'tryingbest.mp3'))\n",
    "        pass\n",
    "\n",
    "if(do_train):\n",
    "    while True:\n",
    "        try:\n",
    "            epoch+=1    \n",
    "            train()\n",
    "            model_eval()\n",
    "\n",
    "        except RuntimeError as e:\n",
    "            playsound(os.path.join(sound_path,'help.mp3'))\n",
    "            model_eval()\n",
    "            continue\n",
    "#             raise e\n",
    "# except TypeError:\n",
    "#     pass\n",
    "  \n",
    "\n",
    "# except KeyboardInterrupt:\n",
    "#     for sound in music_sheet2:\n",
    "#         winsound.Beep(sound[0], sound[1]) \n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
