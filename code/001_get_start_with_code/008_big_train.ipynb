{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from my_modules.log import log,Limit,CounterBreak,CounterMod\n",
    "\n",
    "\n",
    "from my_modules.load_data import MyDataset,ConcatDataset\n",
    "import my_modules.model.lstm as model_modules\n",
    "from my_modules.model.lstm import LSTM_0,move_to_gpu,del_gpu,LSTM_1,LSTM_2,LSTM_3,LSTM_4\n",
    "\n",
    "from my_modules.model.lstmcnn_part3 import LSTMCNN_10,LSTMCNN_10_2\n",
    "from my_modules.model.lstm2cnn_part1 import LSTM2CNN_1,LSTM2CNN_2,LSTM2CNN_3,LSTM2CNN_4\n",
    "from my_modules.model.lstm2cnn_final import LSTM2CNN,LSTM2CNN_2\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import os\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(model_modules.get_used_memory())\n",
    "\n",
    "from playsound import playsound\n",
    "sound_path = r'C:\\Users\\rakna\\Desktop\\AIT_working\\AIT_CP_Project\\code\\notice_sound'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25156, 25156, 25156, 25156, 25156, 25156, 25156, 25156, 25156, 25156, 25156, 25156, 25156, 25156, 25156, 25156, 25156, 25156, 25156, 25156, 25156, 25156, 25156, 25156, 25156, 25156, 25156, 25156, 25156, 25156, 25156, 25156]\n",
      "804992\n",
      "(tensor([[ 2.6753e+00,  8.1925e+00,  1.8993e+01,  ..., -2.5978e+01,\n",
      "         -1.2039e+01, -3.2680e+00],\n",
      "        [-1.2657e+01, -2.5779e+01, -4.6467e+01,  ...,  6.1634e+01,\n",
      "          2.8586e+01, -1.3370e+00],\n",
      "        [-3.5147e+00, -3.1367e+00,  2.4314e+00,  ..., -5.2270e+00,\n",
      "         -4.0622e+00, -3.4219e+00],\n",
      "        ...,\n",
      "        [ 6.2441e+02,  5.8991e+02,  6.3266e+02,  ...,  6.3929e+02,\n",
      "          7.6063e+02,  8.4888e+02],\n",
      "        [ 2.6323e+03,  3.1801e+03,  3.6581e+03,  ...,  6.1361e+03,\n",
      "          6.2719e+03,  6.3632e+03],\n",
      "        [-3.8966e-02, -3.8966e-02, -3.8966e-02,  ...,  2.9033e-02,\n",
      "          2.9033e-02,  2.9033e-02]]), tensor([1., 9.]))\n"
     ]
    }
   ],
   "source": [
    "train_index_movie = [i for i in range(38)]\n",
    "test_index_movie = [i for i in range(len(train_index_movie),40)]\n",
    "\n",
    "\n",
    "people_name = []\n",
    "people_name = [*people_name,*[f's0{i}.dat' for i in range(1,9+1)]]\n",
    "people_name = [*people_name,*[f's{i}.dat' for i in range(10,32+1)]]\n",
    "data_root_path = r'C:\\Users\\rakna\\Desktop\\AIT_working\\AIT_CP_Project\\this_folder_git_ignore\\ori_datasets'\n",
    "\n",
    "data_path = [os.path.join(data_root_path,path) for path in people_name]\n",
    "\n",
    "\n",
    "\n",
    "# window_size = 145*5\n",
    "window_size = 145*10\n",
    "step_window = 10\n",
    "\n",
    "list_train_dataset = [MyDataset(_path,window_size,step_window,train_index_movie,do_noise=True) for _path in data_path]\n",
    "list_test_dataset = [MyDataset(_path,window_size,step_window,test_index_movie) for _path in data_path]\n",
    "\n",
    "\n",
    "data_train = ConcatDataset(*list_train_dataset)\n",
    "data_test = ConcatDataset(*list_test_dataset)\n",
    "\n",
    "\n",
    "print(data_train.len_of_dataset)\n",
    "print(len(data_train)) #804992\n",
    "print(data_train[50000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeForce GTX 1070 Ti\n"
     ]
    }
   ],
   "source": [
    "model_modules.do_gpu = torch.cuda.is_available()\n",
    "# model_modules.do_gpu = False\n",
    "\n",
    "if(model_modules.do_gpu):\n",
    "    print(torch.cuda.get_device_name())\n",
    "else:\n",
    "    print('using CPU')\n",
    "\n",
    "data_loader = DataLoader(data_train,batch_size = 128,shuffle=True,pin_memory=model_modules.do_gpu)\n",
    "data_loader_test  = DataLoader(data_test,batch_size = 128,shuffle=True,pin_memory=model_modules.do_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continue train from epoch 2 best_loss = 7.83\n"
     ]
    }
   ],
   "source": [
    "# input_size = num EEG channels\n",
    "\n",
    "\n",
    "input_size = 40\n",
    "torch.manual_seed(55555)\n",
    "\n",
    "\n",
    "save_folder = r'w_all\\v001'\n",
    "\n",
    "model = LSTM2CNN_2(input_size=input_size,number_layers=1)\n",
    "\n",
    "'''\n",
    "    load w\n",
    "    \n",
    "'''\n",
    "load_w_path = r'\\w_all\\v001\\model_002_7dot83'\n",
    "# load_w_path = None\n",
    "\n",
    "\n",
    "\n",
    "if(load_w_path is not None):\n",
    "    model.load_state_dict(torch.load(r'C:\\Users\\rakna\\Desktop\\AIT_working\\AIT_CP_Project\\this_folder_git_ignore'+load_w_path))\n",
    "\n",
    "best_loss = None\n",
    "epoch = -1\n",
    "if(load_w_path is not None):\n",
    "    name = load_w_path.split('\\\\')[-1]\n",
    "    epoch = int(name.split('_')[-2])\n",
    "    best_loss = float(name.split('_')[-1].replace('dot','.'))\n",
    "\n",
    "print(f\"continue train from epoch {epoch} best_loss = {best_loss}\")\n",
    "\n",
    "\n",
    "'''\n",
    "    tranfer learning\n",
    "'''\n",
    "\n",
    "\n",
    "# load_w_path = r'\\w\\v028\\model_036_0dot90'\n",
    "# load_w_path = r'\\w_s12\\v002\\model_013_4dot29'\n",
    "# model.load_state_dict(torch.load(r'C:\\Users\\rakna\\Desktop\\AIT_working\\AIT_CP_Project\\this_folder_git_ignore'+load_w_path))\n",
    "\n",
    "# epoch => what's epoch now\n",
    "\n",
    "\n",
    "model = move_to_gpu(model)\n",
    "# print(model.eval())\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "\n",
    "\n",
    "# lr_rate = 5e-8\n",
    "# lr_rate = 5e-7\n",
    "lr_rate = 5e-6\n",
    "# lr_rate = 5e-5\n",
    "# lr_rate = 5e-4\n",
    "# lr_rate = 5e-3\n",
    "# lr_rate = 1e-3\n",
    "\n",
    "\n",
    "\n",
    "l2_rate = 1e-4\n",
    "# l2_rate = 8e-3\n",
    "# l2_rate = 1e-3\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters_with_l2(),lr=lr_rate,weight_decay=l2_rate)\n",
    "optimizer_without_l2 = torch.optim.Adam(model.parameters_without_l2(),lr=lr_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                         | 0/6289 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continue train from epoch 2 best_loss = 7.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 6289/6289 [50:36<00:00,  2.07it/s]\n",
      "  0%|                                                                                          | 0/331 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================loss train at epoch 3==============================\n",
      "6.353748863803732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 331/331 [01:52<00:00,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================loss_test at epoch 3==============================\n",
      "7.538434658165785\n",
      "==============================loss test at epoch 3==============================\n",
      "7.538434658165785\n",
      "============================================================save w============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 6289/6289 [50:48<00:00,  2.06it/s]\n",
      "  0%|                                                                                          | 0/331 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================loss train at epoch 4==============================\n",
      "5.9304237855525175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 331/331 [01:52<00:00,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================loss_test at epoch 4==============================\n",
      "7.288969846650553\n",
      "==============================loss test at epoch 4==============================\n",
      "7.288969846650553\n",
      "============================================================save w============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 6289/6289 [50:34<00:00,  2.07it/s]\n",
      "  0%|                                                                                          | 0/331 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================loss train at epoch 5==============================\n",
      "5.67916872463842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 331/331 [01:50<00:00,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================loss_test at epoch 5==============================\n",
      "7.4474542306629194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 6289/6289 [50:28<00:00,  2.08it/s]\n",
      "  0%|                                                                                          | 0/331 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================loss train at epoch 6==============================\n",
      "5.477479313075363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 331/331 [01:50<00:00,  3.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================loss_test at epoch 6==============================\n",
      "7.37816119122001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 6289/6289 [50:22<00:00,  2.08it/s]\n",
      "  0%|                                                                                          | 0/331 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================loss train at epoch 7==============================\n",
      "5.33815198737727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 331/331 [01:49<00:00,  3.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================loss_test at epoch 7==============================\n",
      "7.547589669414878\n",
      "==============================(from CounterMod)loss test at epoch 7==============================\n",
      "7.547589669414878\n",
      "ram gpu 426274816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 6289/6289 [50:22<00:00,  2.08it/s]\n",
      "  0%|                                                                                          | 0/331 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================loss train at epoch 8==============================\n",
      "5.225293342175137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 331/331 [01:49<00:00,  3.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================loss_test at epoch 8==============================\n",
      "7.338678815213575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 6289/6289 [50:33<00:00,  2.07it/s]\n",
      "  0%|                                                                                          | 0/331 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================loss train at epoch 9==============================\n",
      "5.12928677374806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 331/331 [01:51<00:00,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================loss_test at epoch 9==============================\n",
      "7.240411778591191\n",
      "==============================loss test at epoch 9==============================\n",
      "7.240411778591191\n",
      "============================================================save w============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████▍                                                                  | 988/6289 [07:50<42:10,  2.10it/s]"
     ]
    }
   ],
   "source": [
    "print(f\"continue train from epoch {epoch} best_loss = {best_loss}\")\n",
    "\n",
    "pl_1 = Limit(1)\n",
    "pl_1_2 = Limit(1)\n",
    "\n",
    "do_train = True\n",
    "is_limit = False\n",
    "\n",
    "def train(not_ok=0):\n",
    "    pl = Limit(3)\n",
    "    loss_train_batch = 0\n",
    "    c=0\n",
    "    for train_data,label in tqdm(data_loader):\n",
    "\n",
    "        if(is_limit):\n",
    "            if(CounterBreak.set_count(2).count()):\n",
    "                pl_1('limit train_data')\n",
    "                break\n",
    "\n",
    "        train_data = move_to_gpu(train_data)\n",
    "        label = move_to_gpu(label)\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        optimizer_without_l2.zero_grad()\n",
    "        bz = train_data.shape[0]\n",
    "        model.reset_hidden(bz)\n",
    "\n",
    "\n",
    "        if(not_ok==0):\n",
    "            y_hat = (model(train_data))\n",
    "        else:\n",
    "            model(1)\n",
    "\n",
    "        loss = loss_func(y_hat,label)\n",
    "        loss_train_batch+=float(loss)\n",
    "        c+=1\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer_without_l2.step()\n",
    "\n",
    "#         del_gpu(train_data,label)\n",
    "\n",
    "    log(loss_train_batch/c,title=f\"loss train at epoch {epoch}\")\n",
    "def model_eval():\n",
    "    '''\n",
    "                find loss test\n",
    "    '''\n",
    "    global best_loss\n",
    "    loss_test=0\n",
    "    c = 0\n",
    "    with torch.no_grad():\n",
    "        for test_data,y_test in tqdm(data_loader_test):\n",
    "\n",
    "\n",
    "            if(is_limit):\n",
    "                if(CounterBreak.set_count(2).count()):\n",
    "                    pl_1_2('limit test_data')\n",
    "                    break\n",
    "\n",
    "            test_data = move_to_gpu(test_data)    \n",
    "            y_test = move_to_gpu(y_test)\n",
    "\n",
    "            bz = test_data.shape[0]\n",
    "\n",
    "            model.reset_hidden(bz)\n",
    "            y_hat_test = model(test_data)\n",
    "\n",
    "            batch_loss_test = loss_func(y_hat_test,y_test)\n",
    "\n",
    "            loss_test+= float(batch_loss_test)\n",
    "            c+=1\n",
    "\n",
    "#             del_gpu(test_data,y_test)\n",
    "\n",
    "\n",
    "    loss_test = loss_test/c\n",
    "    log(loss_test,title=f\"loss_test at epoch {epoch}\")\n",
    "\n",
    "\n",
    "    rp = r\"C:\\Users\\rakna\\Desktop\\AIT_working\\AIT_CP_Project\\this_folder_git_ignore\"\n",
    "    if(CounterMod.init().set_mod(5).count()):\n",
    "        log(loss_test,title=f\"(from CounterMod)loss test at epoch {epoch}\")\n",
    "        log('ram gpu',torch.cuda.memory_allocated())\n",
    "        torch.save(model.state_dict(), os.path.join(rp,save_folder,f'./autosave_model_{epoch:03}_{\"{:.2f}\".format(loss_test).replace(\".\",\"dot\") }' ) )\n",
    "\n",
    "    if(best_loss is None or loss_test<best_loss):\n",
    "        best_loss=loss_test\n",
    "\n",
    "        torch.save(model.state_dict(), os.path.join(rp,save_folder,f'./model_{epoch:03}_{\"{:.2f}\".format(loss_test).replace(\".\",\"dot\") }' ) )\n",
    "        log(loss_test,title=f\"loss test at epoch {epoch}\")\n",
    "        log(title='save w',n=60)\n",
    "        playsound(os.path.join(sound_path,'got_it.mp3'))\n",
    "    else:\n",
    "        playsound(os.path.join(sound_path,'trying_best.mp3'))\n",
    "\n",
    "must_check =False\n",
    "if(do_train):\n",
    "    while True:\n",
    "        try:\n",
    "            epoch+=1    \n",
    "            if(must_check):\n",
    "                print(\"save check\")\n",
    "                model_eval()\n",
    "                must_check=False\n",
    "            train()\n",
    "            model_eval()\n",
    "    \n",
    "\n",
    "        except RuntimeError as e:\n",
    "            epoch-=1\n",
    "            playsound(os.path.join(sound_path,'help.mp3'))\n",
    "            print(\"Help me\"*10)\n",
    "            must_check=True\n",
    "            continue\n",
    "#             raise e\n",
    "# except TypeError:\n",
    "#     pass\n",
    "  \n",
    "\n",
    "# except KeyboardInterrupt:\n",
    "#     for sound in music_sheet2:\n",
    "#         winsound.Beep(sound[0], sound[1]) \n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
